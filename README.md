# EuroBot - Chatbot de IntegraciÃ³n Regional ğŸŒ

Sistema RAG (Retrieval-Augmented Generation) para consultas sobre el curso de IntegraciÃ³n Regional de Europa y AmÃ©rica.

## ğŸš€ CaracterÃ­sticas

- âœ… Procesamiento automÃ¡tico de PDFs y archivos de texto
- âœ… Sistema RAG con ChromaDB para bÃºsqueda semÃ¡ntica
- âœ… Interfaz web interactiva con Streamlit
- âœ… MenÃº de navegaciÃ³n por unidades
- âœ… Preguntas frecuentes predefinidas
- âœ… Campo de texto para preguntas abiertas
- âœ… Mensajes motivacionales aleatorios
- âœ… Modo nocturno con mensajes de apoyo
- âœ… Historial de conversaciÃ³n
- âœ… Referencias a fuentes consultadas

## ğŸ“‹ Requisitos Previos

1. **Ollama instalado y corriendo**
   ```bash
   # Descargar modelos necesarios
   ollama pull llama3.2
   ollama pull nomic-embed-text
   ```

2. **Python 3.8+**

## ğŸ”§ InstalaciÃ³n

1. Instalar dependencias:
   ```bash
   pip install -r requirements.txt
   ```

2. Agregar documentos del curso:
   - Coloca todos los PDFs y archivos de texto en la carpeta `documentos/`

3. Ejecutar la aplicaciÃ³n:
   ```bash
   streamlit run chatbot_rag.py
   ```

## ğŸ“ Estructura del Proyecto

```
Proyecto_ChatBot/
â”œâ”€â”€ chatbot_rag.py          # AplicaciÃ³n principal
â”œâ”€â”€ app.py                  # Script de prueba inicial
â”œâ”€â”€ requirements.txt        # Dependencias
â”œâ”€â”€ documentos/            # PDFs y documentos del curso
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ chroma_db/             # Base de datos vectorial (se crea automÃ¡ticamente)
â””â”€â”€ datos_curso.txt        # Documento de ejemplo
```

## ğŸ¯ Uso

1. **Primera vez:**
   - Abre la aplicaciÃ³n
   - Haz clic en "ğŸ”„ Procesar Documentos" en el menÃº lateral
   - Espera a que se procesen todos los archivos

2. **Navegar:**
   - Usa los botones de unidades en el menÃº lateral
   - Haz clic en preguntas frecuentes
   - O escribe tu propia pregunta en el campo de texto

3. **Funcionalidades:**
   - Ver fuentes consultadas (expandir secciÃ³n)
   - Limpiar historial de chat
   - Mensajes motivacionales aleatorios
   - Mensajes especiales en horario nocturno (10 PM - 6 AM)

## ğŸŒ Despliegue

### OpciÃ³n 1: Streamlit Cloud (Recomendado para pruebas)
1. Sube el proyecto a GitHub
2. Conecta con Streamlit Cloud
3. **Nota:** Necesitas configurar Ollama en un servidor accesible

### OpciÃ³n 2: Servidor VPS
1. Instala Ollama en el servidor
2. Despliega con Docker o directamente
3. Configura nginx como reverse proxy

## ğŸ¨ PersonalizaciÃ³n

- **Agregar mÃ¡s preguntas frecuentes:** Edita la lista `preguntas_freq` en `chatbot_rag.py`
- **Cambiar unidades:** Modifica el diccionario `unidades`
- **Ajustar mensajes motivacionales:** Edita la funciÃ³n `get_mensaje_motivacional()`
- **Cambiar modelo:** Modifica `model='llama3.2'` por otro modelo de Ollama

## ğŸ“Š Componentes TÃ©cnicos

- **Frontend:** Streamlit
- **LLM:** Ollama con llama3.2
- **Embeddings:** nomic-embed-text
- **Vector Store:** ChromaDB
- **Procesamiento PDF:** pypdf

## ğŸ› Troubleshooting

**Error: "Ollama no estÃ¡ disponible"**
- Verifica que Ollama estÃ© corriendo
- Ejecuta: `ollama list` para ver modelos instalados

**Error: "No se encontraron documentos"**
- AsegÃºrate de tener archivos en la carpeta `documentos/`
- Formatos soportados: PDF, TXT

**Respuestas lentas:**
- Normal en CPU, considera usar GPU
- Reduce el nÃºmero de resultados en bÃºsqueda (n_results)

## ğŸ‘¥ CrÃ©ditos

Proyecto desarrollado para el curso de IntegraciÃ³n Regional de Europa y AmÃ©rica.

## ğŸ“ Licencia

Proyecto acadÃ©mico - Universidad AutÃ³noma del Estado de MÃ©xico
